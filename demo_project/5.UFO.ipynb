{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Build a Web App to use a ML Model\n",
    "\n",
    "1. 学习链接：https://github.com/microsoft/ML-For-Beginners/blob/main/3-Web-App/1-Web-App/README.md\n",
    "2. 数据链接：https://www.kaggle.com/datasets/NUFORC/ufo-sightings/data\n",
    "3. 学习目标：模型保存，并在 Web 应用中用于预测\n",
    "4. 关于数据集\n",
    "- 该数据集包含了过去一个世纪中 8 万多条 UFO 目击报告。由于这些报告可以追溯到 20 世纪，部分较早的数据可能不够清晰或不完整。数据字段包括：城市、州、时间、描述以及每次目击的持续时长。\n",
    "\n",
    "- 两个版本：清洗版（scrubbed） 和 完整版（complete）\n",
    "    - 完整数据中包含一些问题记录，例如：目击地点未找到或为空（占 0.8146%），时间信息错误或缺失（占 8.0237%）\n",
    "\n",
    "- 研究启发（Inspiration）\n",
    "    - 哪些地区最有可能出现 UFO 目击事件？\n",
    "    - UFO 目击是否随时间呈现某种趋势？是否具有聚集性或季节性？\n",
    "    - UFO 目击事件的聚集是否与某些地标有关，例如机场或政府研究中心？\n",
    "    - 最常见的 UFO 描述是什么？\n",
    "5. 依赖环境\n",
    "\n",
    "        pip3 install pandas numpy scikit-learn tensorflow flask joblib"
   ],
   "id": "a8b87e940f9c79da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T06:54:19.340151Z",
     "start_time": "2026-01-22T06:54:19.223446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/yfan/Downloads/archive/scrubbed.csv\", low_memory=False)\n",
    "\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df = df.dropna(subset=['duration (seconds)', 'latitude', 'longitude ', 'shape'])\n",
    "df.head(5)\n"
   ],
   "id": "420fd3650428a315",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['datetime', 'city', 'state', 'country', 'shape', 'duration (seconds)', 'duration (hours/min)', 'comments', 'date posted', 'latitude', 'longitude ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           datetime                  city state country     shape  \\\n",
       "0  10/10/1949 20:30            san marcos    tx      us  cylinder   \n",
       "1  10/10/1949 21:00          lackland afb    tx     NaN     light   \n",
       "2  10/10/1955 17:00  chester (uk/england)   NaN      gb    circle   \n",
       "3  10/10/1956 21:00                  edna    tx      us    circle   \n",
       "4  10/10/1960 20:00               kaneohe    hi      us     light   \n",
       "\n",
       "  duration (seconds) duration (hours/min)  \\\n",
       "0               2700           45 minutes   \n",
       "1               7200              1-2 hrs   \n",
       "2                 20           20 seconds   \n",
       "3                 20             1/2 hour   \n",
       "4                900           15 minutes   \n",
       "\n",
       "                                            comments date posted    latitude  \\\n",
       "0  This event took place in early fall around 194...   4/27/2004  29.8830556   \n",
       "1  1949 Lackland AFB&#44 TX.  Lights racing acros...  12/16/2005    29.38421   \n",
       "2  Green/Orange circular disc over Chester&#44 En...   1/21/2008        53.2   \n",
       "3  My older brother and twin sister were leaving ...   1/17/2004  28.9783333   \n",
       "4  AS a Marine 1st Lt. flying an FJ4B fighter/att...   1/22/2004  21.4180556   \n",
       "\n",
       "   longitude   \n",
       "0  -97.941111  \n",
       "1  -98.581082  \n",
       "2   -2.916667  \n",
       "3  -96.645833  \n",
       "4 -157.803611  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration (seconds)</th>\n",
       "      <th>duration (hours/min)</th>\n",
       "      <th>comments</th>\n",
       "      <th>date posted</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/10/1949 20:30</td>\n",
       "      <td>san marcos</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>45 minutes</td>\n",
       "      <td>This event took place in early fall around 194...</td>\n",
       "      <td>4/27/2004</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/10/1949 21:00</td>\n",
       "      <td>lackland afb</td>\n",
       "      <td>tx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>light</td>\n",
       "      <td>7200</td>\n",
       "      <td>1-2 hrs</td>\n",
       "      <td>1949 Lackland AFB&amp;#44 TX.  Lights racing acros...</td>\n",
       "      <td>12/16/2005</td>\n",
       "      <td>29.38421</td>\n",
       "      <td>-98.581082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/10/1955 17:00</td>\n",
       "      <td>chester (uk/england)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gb</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>20 seconds</td>\n",
       "      <td>Green/Orange circular disc over Chester&amp;#44 En...</td>\n",
       "      <td>1/21/2008</td>\n",
       "      <td>53.2</td>\n",
       "      <td>-2.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/10/1956 21:00</td>\n",
       "      <td>edna</td>\n",
       "      <td>tx</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>1/2 hour</td>\n",
       "      <td>My older brother and twin sister were leaving ...</td>\n",
       "      <td>1/17/2004</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/10/1960 20:00</td>\n",
       "      <td>kaneohe</td>\n",
       "      <td>hi</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>AS a Marine 1st Lt. flying an FJ4B fighter/att...</td>\n",
       "      <td>1/22/2004</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.803611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T06:53:08.953603Z",
     "start_time": "2026-01-22T06:53:03.194643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pickle\n",
    "\n",
    "def train_model():\n",
    "    print(\"正在加载并清洗数据...\")\n",
    "    # 1. 加载数据\n",
    "    df = pd.read_csv('/Users/yfan/Downloads/archive/scrubbed.csv', low_memory=False)\n",
    "\n",
    "    # 2. 强力清洗数值列 (解决 ValueError: could not convert string to float)\n",
    "    def clean_col(col_name):\n",
    "        # 移除除数字、小数点、负号以外的任何字符\n",
    "        df[col_name] = df[col_name].astype(str).str.replace(r'[^0-9.-]', '', regex=True)\n",
    "        return pd.to_numeric(df[col_name], errors='coerce')\n",
    "\n",
    "    df['duration (seconds)'] = clean_col('duration (seconds)')\n",
    "    df['latitude'] = clean_col('latitude')\n",
    "    # 注意原始列名中 'longitude' 后面可能带有一个空格\n",
    "    df['longitude '] = clean_col('longitude')\n",
    "\n",
    "    # 3. 处理缺失值和标签\n",
    "    df = df.dropna(subset=['duration (seconds)', 'latitude', 'longitude', 'shape'])\n",
    "\n",
    "    # 过滤掉出现次数极少的形状，提高模型稳定性\n",
    "    shape_counts = df['shape'].value_counts()\n",
    "    df = df[df['shape'].isin(shape_counts[shape_counts > 100].index)]\n",
    "\n",
    "    X = df[['duration (seconds)', 'latitude', 'longitude']].values\n",
    "    y = df['shape'].values\n",
    "\n",
    "    # 4. 编码与标准化\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 5. 构建深度学习模型\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(len(le.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 6. 训练模型\n",
    "    print(\"开始训练...\")\n",
    "    model.fit(X_train, y_train, epochs=15, batch_size=64, validation_split=0.1, verbose=1)\n",
    "\n",
    "    # 7. 保存所有组件\n",
    "    model.save('ufo_model.h5')\n",
    "    with open('scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    with open('label_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(le, f)\n",
    "\n",
    "    print(\"\\n训练完成！已生成: ufo_model.h5, scaler.pkl, label_encoder.pkl\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()"
   ],
   "id": "f96d12e97a1abf67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载并清洗数据...\n",
      "开始训练...\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 447us/step - accuracy: 0.1976 - loss: 2.7037 - val_accuracy: 0.2126 - val_loss: 2.6418\n",
      "Epoch 2/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 396us/step - accuracy: 0.2119 - loss: 2.6388 - val_accuracy: 0.2148 - val_loss: 2.6439\n",
      "Epoch 3/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 379us/step - accuracy: 0.2130 - loss: 2.6281 - val_accuracy: 0.2150 - val_loss: 2.6403\n",
      "Epoch 4/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 396us/step - accuracy: 0.2133 - loss: 2.6239 - val_accuracy: 0.2151 - val_loss: 2.6293\n",
      "Epoch 5/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 386us/step - accuracy: 0.2134 - loss: 2.6213 - val_accuracy: 0.2153 - val_loss: 2.6299\n",
      "Epoch 6/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 389us/step - accuracy: 0.2134 - loss: 2.6204 - val_accuracy: 0.2153 - val_loss: 2.6292\n",
      "Epoch 7/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 402us/step - accuracy: 0.2134 - loss: 2.6188 - val_accuracy: 0.2150 - val_loss: 2.6420\n",
      "Epoch 8/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 394us/step - accuracy: 0.2136 - loss: 2.6181 - val_accuracy: 0.2153 - val_loss: 2.6241\n",
      "Epoch 9/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 404us/step - accuracy: 0.2134 - loss: 2.6158 - val_accuracy: 0.2151 - val_loss: 2.6310\n",
      "Epoch 10/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 389us/step - accuracy: 0.2134 - loss: 2.6151 - val_accuracy: 0.2151 - val_loss: 2.6310\n",
      "Epoch 11/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 385us/step - accuracy: 0.2135 - loss: 2.6141 - val_accuracy: 0.2151 - val_loss: 2.6296\n",
      "Epoch 12/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 379us/step - accuracy: 0.2134 - loss: 2.6129 - val_accuracy: 0.2150 - val_loss: 2.6328\n",
      "Epoch 13/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 379us/step - accuracy: 0.2134 - loss: 2.6127 - val_accuracy: 0.2151 - val_loss: 2.6297\n",
      "Epoch 14/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 380us/step - accuracy: 0.2134 - loss: 2.6129 - val_accuracy: 0.2151 - val_loss: 2.6253\n",
      "Epoch 15/15\n",
      "\u001B[1m882/882\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 377us/step - accuracy: 0.2134 - loss: 2.6110 - val_accuracy: 0.2151 - val_loss: 2.6285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练完成！已生成: ufo_model.h5, scaler.pkl, label_encoder.pkl\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
