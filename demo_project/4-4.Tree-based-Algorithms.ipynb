{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 机器学习笔记之树模型\n",
    "\n",
    "## 1.树模型概括\n",
    "\n",
    "| 模型类型 | 代表模型                               | 核心特点与适用场景 | Python 函数 / 来源                                                                                                               |\n",
    "|---------|------------------------------------|-------------------|------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 单一模型 | 决策树                                | if-else规则分割数据；简单直观易解释；易过拟合；适合小数据和需要解释的场景 | sklearn.tree.DecisionTree(Classifier/Regressor)                                                                              |\n",
    "| Bagging | 随机森林                               | 多树并行投票；稳定性高，抗过拟合；计算成本高；适合表格数据基线模型 | sklearn.ensemble.RandomForest(Classifier/Regressor)                                                                          |\n",
    "| Boosting | GBDT                               | 顺序学习残差；预测精度高；训练慢参数多；适合中等规模高性能场景 | sklearn.ensemble.GradientBoosting(Classifier/Regressor)                                                                      |\n",
    "| Boosting优化 | XGBoost <br>LightGBM <br> CatBoost | **XGBoost**：GBDT优化版，功能全面性能强，参数复杂，竞赛工业常用<br>**LightGBM**：直方图算法，训练快内存低，小数据易过拟合，适合海量数据<br>**CatBoost**：自动处理类别特征，预处理简单，训练较慢，适合类别特征多的数据 | xgboost.XGB(Classifier/Regressor)    (由**陈天奇**在**华盛顿大学**开发) <br>lightgbm.LGBM(Classifier/Regressor)    **(微软:Microsoft)** <br> catboost.CatBoost(Classifier/Regressor)    **(Yandex:俄罗斯科技公司)** |"
   ],
   "id": "6d31347980e74ee9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. demo project\n",
    "\n",
    "### 2-1:InterDIA\n",
    "\n",
    "[Huang L , Liu P , Huang X .InterDIA: Interpretable prediction of drug-induced autoimmunity through ensemble machine learning approaches[J].Toxicology, 2025:511.DOI:10.1016/j.tox.2025.154064.](https://www.sciencedirect.com/science/article/abs/pii/S0300483X25000204)\n",
    "\n",
    "[https://github.com/Huangxiaojie2024/InterDIA](https://github.com/Huangxiaojie2024/InterDIA)\n",
    "\n",
    "**流程图**\n",
    "\n",
    "<img src=\"./InterDIA.jpg\" width=\"700\" height=\"250\">\n",
    "\n",
    "#### 知识点\n",
    "\n",
    "1.  处理不平衡数据imbalanced-ensemble\n",
    "\n",
    "    在分类问题中，如果数据集的各类别样本数量差异较大，可能会导致模型偏向预测多数类，从而影响模型的性能。常见的方法是使用 SMOTE（Synthetic Minority Over-sampling Technique）算法。\n",
    "\n",
    "| 模型类别 | 核心思想 | 代表模型 | 简要说明 |\n",
    "|---------|---------|---------|---------|\n",
    "| **🔄 重采样集成**<br>*(Resampling-based)* | 在训练每个基学习器之前，先对训练数据进行重采样（如过采样或欠采样）以平衡类别分布。 | **SMOTEBoost**<br>**RUSBoost**<br>**UnderBagging**<br>**OverBagging**<br>**SMOTEBagging** | 将经典的SMOTE、随机过采样/欠采样与Boosting或Bagging框架结合。 |\n",
    "| **⚖️ 代价敏感集成**<br>*(Cost-sensitive)* | 不改变数据分布，而是让学习算法在训练过程中更加关注误分少数类样本带来的高昂代价。 | **AdaCost**<br>**AsymBoost** | 通过修改算法的损失函数或权重更新机制，实现代价敏感学习。 |\n",
    "| **✨ 自适应采样集成**<br>*(Adaptive Sampling)* | 根据之前基学习器的表现，自适应地调整下一次采样的样本分布，专注于难以分类的样本。 | **BalanceCascade**<br>**Self-Paced Ensemble (SPE)** | 动态地、有选择性地进行采样，效率和学习效果往往更好。 |\n",
    "| **🔄 混合方法**<br>*(Hybrid Methods)* | 将多种不平衡处理技术（如采样和代价敏感）结合在一起，或设计新的集成策略。 | **EasyEnsemble**<br>**BalanceCascade**<br>*(广义上也属此类)* | 综合不同策略的优势，以期获得更鲁棒的模型。 |\n",
    "\n",
    "2.  模型选择\n",
    "  - Balanced Random Forest (BRF)\n",
    "  - Easy Ensemble Classifier (EEC)\n",
    "  - XGBoost with Balanced Bagging (BBC+XGBoost)\n",
    "  - Gradient Boosting with Balanced Bagging (BBC+GBDT)\n",
    "  - LightGBM with Balanced Bagging (BBC+LightGBM)"
   ],
   "id": "8b510d72f0d61a74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2-2:IntelliGenes\n",
    "\n",
    "[DeGroat W, Mendhe D, Bhusari A, et al. IntelliGenes: a novel machine learning pipeline for biomarker discovery and predictive analysis using multi-genomic profiles[J]. Bioinformatics, 2023, 39(12): btad755.](https://academic.oup.com/bioinformatics/article/39/12/btad755/7473370)\n",
    "\n",
    "https://github.com/drzeeshanahmed/intelligenes\n",
    "\n",
    "流程图\n",
    "\n",
    "![IntelliGenes](./IntelliGenes.jpg)\n",
    "\n",
    "特真选取的最重要函数from sklearn.feature_selection import SelectKBest, chi2, f_classif, RFE\n",
    "\n",
    "SelectKBest：对应的函数chi2, f_classif选取最好的10个特征，这里很重要还增加了一个p value值\n",
    "\n",
    "REF：递归特征消除的特征排序\n",
    "\n",
    "pearson 相关性系数筛选\n",
    "\n",
    "最后选取共有的特征作为最终的biomarker\n"
   ],
   "id": "f86475bf430db74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# (Packages/Libraries) Matrix Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# (Packages/Libraries) Statistical Analysis & Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# (Packages/Libraries) Miscellaneous\n",
    "import argparse\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "class FeatureSelection:\n",
    "\n",
    "    def __init__(self: 'FeatureSelection', cgit_file: str, output_dir: str, random_state: 42, test_size: 0.3, use_rfe = True, use_pearson = True, use_chi2 = True, use_anova = True, use_normalization = False):\n",
    "        self.cgit_file = cgit_file\n",
    "        self.output_dir = output_dir\n",
    "        self.random_state = random_state\n",
    "        self.test_size = test_size\n",
    "        self.use_rfe = use_rfe\n",
    "        self.use_pearson = use_pearson\n",
    "        self.use_chi2 = use_chi2\n",
    "        self.use_anova = use_anova\n",
    "        self.use_normalization = use_normalization\n",
    "\n",
    "        self.df = pd.read_csv(self.cgit_file)\n",
    "\n",
    "        self.y = self.df['Type']\n",
    "        self.X = self.df.drop(['Type', 'ID'], axis = 1)\n",
    "\n",
    "        if self.use_normalization:\n",
    "            self.X = pd.DataFrame(MinMaxScaler().fit_transform(self.X), columns = self.X.columns)\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = self.test_size, random_state = self.random_state)\n",
    "\n",
    "        self.selectors = []\n",
    "\n",
    "    def rfe_selector(self: 'FeatureSelection'):\n",
    "        if self.use_rfe:\n",
    "            print(\"Recursive Feature Elimination...\")\n",
    "            rfe_selection = RFE(estimator = DecisionTreeClassifier(random_state = self.random_state), n_features_to_select = 1).fit(self.X_train, self.y_train)\n",
    "            rfe_df = pd.DataFrame({'attributes': self.X_train.columns,\n",
    "                                   'rfe_rankings': rfe_selection.ranking_})\n",
    "\n",
    "            rfe_df = rfe_df.sort_values(by = 'rfe_rankings').loc[rfe_df['rfe_rankings'] <= int((self.df.shape[1] - 2) * .10)]\n",
    "            return rfe_df\n",
    "        return None\n",
    "\n",
    "    def pearson_selector(self: 'FeatureSelection'):\n",
    "        if self.use_pearson:\n",
    "            print(\"Pearson's Correlation...\")\n",
    "            pearson_selection = [pearsonr(self.X_train[column], self.y_train) for column in self.X.columns]\n",
    "            pearson_df = pd.DataFrame({'attributes': self.X_train.columns,\n",
    "                                       'pearson_p-value': [corr[1] for corr in pearson_selection]})\n",
    "\n",
    "            pearson_df = pearson_df[pearson_df['pearson_p-value'] < 0.05]\n",
    "            return pearson_df\n",
    "        return None\n",
    "\n",
    "    def chi2_selector(self: 'FeatureSelection'):\n",
    "        if self.use_chi2:\n",
    "            print(\"Chi-Square Test...\")\n",
    "            chi2_selection = SelectKBest(score_func = chi2, k = 10).fit(self.X_train, self.y_train)\n",
    "            chi2_df = pd.DataFrame({'attributes': self.X_train.columns,\n",
    "                                    'chi2_p-value': chi2_selection.pvalues_})\n",
    "\n",
    "            chi2_df = chi2_df[chi2_df['chi2_p-value'] < 0.05]\n",
    "            return chi2_df\n",
    "        return None\n",
    "\n",
    "    def anova_selector(self: 'FeatureSelection'):\n",
    "        if self.use_anova:\n",
    "            print(\"ANOVA...\")\n",
    "            anova_selection = SelectKBest(score_func = f_classif, k = 10).fit(self.X_train, self.y_train)\n",
    "            anova_df = pd.DataFrame({'attributes': self.X_train.columns,\n",
    "                                     'anova_p-value': anova_selection.pvalues_})\n",
    "\n",
    "            anova_df = anova_df[anova_df['anova_p-value'] < 0.05]\n",
    "            return anova_df\n",
    "        return None\n",
    "\n",
    "    def execute_selectors(self: 'FeatureSelection'):\n",
    "        self.selectors = [self.rfe_selector(),\n",
    "                          self.pearson_selector(),\n",
    "                          self.chi2_selector(),\n",
    "                          self.anova_selector()]\n",
    "\n",
    "        self.selectors = [df for df in self.selectors if df is not None]\n",
    "\n",
    "    def selected_attributes(self: 'FeatureSelection'):\n",
    "        selected_attributes = pd.DataFrame({'attributes': self.X_train.columns})\n",
    "        for df in self.selectors:\n",
    "            selected_attributes = selected_attributes.merge(df, how = 'inner', on = 'attributes')\n",
    "\n",
    "        selector_cols = ['rfe_rankings', 'pearson_p-value', 'chi2_p-value', 'anova_p-value']\n",
    "        selectors_used = [col for col in selector_cols if col in selected_attributes.columns]\n",
    "        if any(not self.__dict__[f\"use_{selector.split('_')[0]}\"] for selector in selectors_used):\n",
    "            selected_attributes = selected_attributes.dropna(subset = selectors_used, how = 'any')\n",
    "\n",
    "        selected_attributes = selected_attributes.rename(columns={\n",
    "            'attributes': 'Features',\n",
    "            'rfe_rankings': 'RFE Rankings',\n",
    "            'pearson_p-value': \"Pearson's Correlation (p-value)\",\n",
    "            'chi2_p-value': 'Chi-Square Test (p-value)',\n",
    "            'anova_p-value': 'ANOVA (p-value)'\n",
    "        })\n",
    "\n",
    "        return selected_attributes\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\")\n",
    "    print(\"IntelliGenes Feature Selection/Biomarker Location...\")\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-i', '--cgit_file', required = True)\n",
    "    parser.add_argument('-o', '--output_dir', required = True)\n",
    "    parser.add_argument('--random_state', type = int, default = 42)\n",
    "    parser.add_argument('--test_size', type = float, default = 0.3)\n",
    "    parser.add_argument('--no_rfe', action = 'store_true')\n",
    "    parser.add_argument('--no_pearson', action = 'store_true')\n",
    "    parser.add_argument('--no_chi2', action = 'store_true')\n",
    "    parser.add_argument('--no_anova', action = 'store_true')\n",
    "    parser.add_argument('--normalize', action = 'store_true')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    pipeline = FeatureSelection(\n",
    "        cgit_file  = args.cgit_file,\n",
    "        output_dir = args.output_dir,\n",
    "        random_state = args.random_state,\n",
    "        test_size = args.test_size,\n",
    "        use_rfe = not args.no_rfe,\n",
    "        use_pearson = not args.no_pearson,\n",
    "        use_chi2 = not args.no_chi2,\n",
    "        use_anova = not args.no_anova,\n",
    "        use_normalization = args.normalize\n",
    "    )\n",
    "\n",
    "    pipeline.execute_selectors()\n",
    "    features_df = pipeline.selected_attributes()\n",
    "\n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)\n",
    "\n",
    "    file_name = Path(args.cgit_file).stem\n",
    "    features_name = f\"{file_name}_{datetime.now().strftime('%m-%d-%Y-%I-%M-%S-%p')}_Selected-Features.csv\"\n",
    "    features_file = os.path.join(args.output_dir, features_name)\n",
    "\n",
    "    features_df.to_csv(features_file, index = False)\n",
    "    print(\"\\n Selected Features:\", features_file, \"\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "id": "ea0f1b104e64839"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
